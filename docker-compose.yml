services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    environment:
      - CLUSTER_NAME=test
    ports:
      - "9870:9870"   # Web UI HDFS
      - "8020:8020"   # RPC
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    env_file:
      - ./.env
    networks:
      - bigdata

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    environment:
      - SERVICE_PRECONDITION=namenode:9870
    ports:
      - "9864:9864"
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    env_file:
      - ./.env
    networks:
      - bigdata

  spark-master:
    image: apache/spark:3.5.0
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_NO_DAEMONIZE=true
      - HOME=/root
      - HADOOP_CONF_DIR=/opt/hadoop/conf
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
      --host spark-master
      --port 7077
      --webui-port 8080
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - ./ivy2:/root/.ivy2
      - ./hadoop_config:/opt/hadoop/conf
    networks:
      - bigdata
    depends_on:
      - namenode
      - datanode

  spark-worker:
    image: apache/spark:3.5.0
    container_name: spark-worker
    environment:
      - SPARK_NO_DAEMONIZE=true
      - HOME=/root
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker
      spark://spark-master:7077
      --webui-port 8081
    depends_on:
      - spark-master
      - namenode
    ports:
      - "8081:8081"
    volumes:
      - ./ivy2:/root/.ivy2
    networks:
      - bigdata
  
  spark-thrift:
    image: apache/spark:3.5.0
    container_name: spark-thrift
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_NO_DAEMONIZE=true
      - HADOOP_CONF_DIR=/opt/hadoop/conf
    command: >
      /opt/spark/sbin/start-thriftserver.sh
      --class org.apache.spark.sql.hive.thriftserver.HiveThriftServer2
      --master spark://spark-master:7077
      --hiveconf hive.server2.thrift.port=10000
      --hiveconf hive.server2.thrift.bind.host=0.0.0.0
      --conf spark.sql.catalogImplementation=in-memory
    ports:
      - "10000:10000"
    networks:
      - bigdata
    depends_on:
      - spark-master
      - namenode
      - datanode

volumes:
  hadoop_namenode:
  hadoop_datanode:

networks:
  bigdata:
    driver: bridge
